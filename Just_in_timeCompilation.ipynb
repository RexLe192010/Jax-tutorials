{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How Jax transformations work"
      ],
      "metadata": {
        "id": "YKCrZl8D-Cjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we discussed that JAX allows us to transform Python functions. JAX accomplishes this by reducing each function into a sequence of primitive operations, each representing one fundamental unit of computation.\n",
        "\n",
        "One way to see the sequence of primitives behind a function is using jax.make_jaxpr():"
      ],
      "metadata": {
        "id": "2qnTT7y1-N-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "global_list = []\n",
        "\n",
        "def log2(x):\n",
        "  global_list.append(x)\n",
        "  print(\"Pinted x:\", x) # x is a traced object during the execution of the function.\n",
        "  ln_x = jnp.log(x)\n",
        "  ln_2 = jnp.log(2.0)\n",
        "  return ln_x / ln_2\n",
        "\n",
        "print(jax.make_jaxpr(log2)(3.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTZj0nob-UG7",
        "outputId": "b1bcce8f-a366-4cc6-9dd5-82df42f240ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinted x: Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace>\n",
            "{ lambda ; a:f32[]. let\n",
            "    b:f32[] = log a\n",
            "    c:f32[] = log 2.0\n",
            "    d:f32[] = div b c\n",
            "  in (d,) }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When tracing, JAX wraps each argument by a tracer object. These tracers then record all JAX operations performed on them during the function call (which happens in regular Python). Then, JAX uses the tracer records to reconstruct the entire function. The output of that reconstruction is the jaxpr. Since the tracers do not record the Python side-effects, they do not appear in the jaxpr. However, the side-effects still happen during the trace itself.\n",
        "\n",
        "Note: the Python print() function is not pure: the text output is a side-effect of the function. Therefore, any print() calls will only happen during tracing, and will not appear in the jaxpr."
      ],
      "metadata": {
        "id": "lTjDwC7m_bka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fact that the Python code runs at least once is strictly an implementation detail, and so shouldn’t be relied upon. However, it’s useful to understand as you can use it when debugging to print out intermediate values of a computation.\n",
        "\n",
        "A key thing to understand is that a jaxpr captures the function as executed on the parameters given to it. For example, if we have a Python conditional, the jaxpr will only know about the branch we take:"
      ],
      "metadata": {
        "id": "rWFjBrB5AGWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log2_if_rank_2(x):\n",
        "  if x.ndim == 2:\n",
        "    ln_x = jnp.log(x)\n",
        "    ln_2 = jnp.log(2.0)\n",
        "    return ln_x / ln_2\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "print(jax.make_jaxpr(log2_if_rank_2)(jax.numpy.array([1, 2, 3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VshTvclgAJIh",
        "outputId": "d7db65db-34aa-4312-f4d2-88770a376b40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ lambda ; a:i32[3]. let  in (a,) }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JIT compiling a function"
      ],
      "metadata": {
        "id": "wedguNLCFLao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As explained before, JAX enables operations to execute on CPU/GPU/TPU using the same code. Let’s look at an example of computing a Scaled Exponential Linear Unit (SELU), an operation commonly used in deep learning:"
      ],
      "metadata": {
        "id": "-y1JVJN5FTif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def selu(x, alpha=1.67, lambda_=1.05):\n",
        "  return lambda_ * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
        "\n",
        "x = jnp.arange(1000000)\n",
        "%timeit selu(x).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4lPPiNLFURW",
        "outputId": "5db213e5-3556-40b6-e0ff-97c6eeb30217"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.8 ms ± 4.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above is sending one operation at a time to the accelerator. This limits the ability of the XLA compiler to optimize our functions.\n",
        "\n",
        "Naturally, what we want to do is give the XLA compiler as much code as possible, so it can fully optimize it. For this purpose, JAX provides the jax.jit() transformation, which will JIT compile a JAX-compatible function. The example below shows how to use JIT to speed up the previous function."
      ],
      "metadata": {
        "id": "YHmF19RPFWG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selu_jit = jax.jit(selu)\n",
        "\n",
        "# Pre-compile the function before timing...\n",
        "selu_jit(x).block_until_ready()\n",
        "\n",
        "%timeit selu_jit(x).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlVaavj5FXq_",
        "outputId": "4c2d8acb-7fa0-464f-c17d-c5f4ee528898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.71 ms ± 623 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s what just happened:\n",
        "\n",
        "We defined selu_jit as the compiled version of selu.\n",
        "\n",
        "We called selu_jit once on x. This is where JAX does its tracing – it needs to have some inputs to wrap in tracers, after all. The jaxpr is then compiled using XLA into very efficient code optimized for your GPU or TPU. Finally, the compiled code is executed to satisfy the call. Subsequent calls to selu_jit will use the compiled code directly, skipping the python implementation entirely. (If we didn’t include the warm-up call separately, everything would still work, but then the compilation time would be included in the benchmark. It would still be faster, because we run many loops in the benchmark, but it wouldn’t be a fair comparison.)\n",
        "\n",
        "We timed the execution speed of the compiled version. (Note the use of block_until_ready(), which is required due to JAX’s Asynchronous dispatch)."
      ],
      "metadata": {
        "id": "4Rt_CLa-FbxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JIT everything?"
      ],
      "metadata": {
        "id": "-bc7g9iPGL9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After going through the example above, you might be wondering whether we should simply apply jax.jit() to every function. To understand why this is not the case, and when we should/shouldn’t apply jit, let’s first check some cases where JIT doesn’t work."
      ],
      "metadata": {
        "id": "vRfZAyucGNqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Condition on value of x.\n",
        "\n",
        "def f(x):\n",
        "  if x > 0:\n",
        "    return x\n",
        "  else:\n",
        "    return 2 * x\n",
        "\n",
        "jax.jit(f)(10)  # Raises an error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "jphZHLpnGOv_",
        "outputId": "4721305d-c499-4e6e-da1a-86fb07182ce7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-7-2956679937.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2956679937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raises an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-2956679937.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTracerBoolConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-7-2956679937.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument x.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# While loop conditioned on x and n.\n",
        "\n",
        "def g(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    i += 1\n",
        "  return x + i\n",
        "\n",
        "jax.jit(g)(10, 20)  # Raises an error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "jMMlgir9GSiO",
        "outputId": "46733823-70e8-4a96-b59d-dbf54f61a42a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function g at /tmp/ipython-input-8-722961019.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-722961019.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raises an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-8-722961019.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTracerBoolConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function g at /tmp/ipython-input-8-722961019.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument n.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem in both cases is that we tried to condition the trace-time flow of the program using runtime values. Traced values within JIT, like x and n here, can only affect control flow via their static attributes: such as shape or dtype, and not via their values. For more detail on the interaction between Python control flow and JAX, see Control flow and logical operators with JIT.\n",
        "\n",
        "One way to deal with this problem is to rewrite the code to avoid conditionals on value. Another is to use special Control flow operators like jax.lax.cond(). However, sometimes that is not possible or practical. In that case, you can consider JIT-compiling only part of the function. For example, if the most computationally expensive part of the function is inside the loop, we can JIT-compile just that inner part (though make sure to check the next section on caching to avoid shooting yourself in the foot):"
      ],
      "metadata": {
        "id": "yZ_96Jd1GiE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# While loop conditioned on x and n with a jitted body.\n",
        "\n",
        "@jax.jit\n",
        "def loop_body(prev_i): # jit on the loop body\n",
        "  return prev_i + 1\n",
        "\n",
        "def g_inner_jitted(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    i = loop_body(i)\n",
        "  return x + i\n",
        "\n",
        "g_inner_jitted(10, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-c5qK1cGjX3",
        "outputId": "db6b5484-8804-4877-b099-91644156f543"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(30, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Marking arguments as static"
      ],
      "metadata": {
        "id": "iZm7YD9eHWHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we really need to JIT-compile a function that has a condition on the value of an input, we can tell JAX to help itself to a less abstract tracer for a particular input by specifying static_argnums or static_argnames. The cost of this is that the resulting jaxpr and compiled artifact depends on the particular value passed, and so JAX will have to re-compile the function for every new value of the specified static input. It is only a good strategy if the function is guaranteed to see a limited set of static values."
      ],
      "metadata": {
        "id": "I2RoiD71IJtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_jit_correct = jax.jit(f, static_argnums=0) # this means the 0-th (the first) variable is static\n",
        "print(f_jit_correct(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqITQTndIKzH",
        "outputId": "72851e4c-7f85-4032-8c39-f9f7e62ce940"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_jit_correct = jax.jit(g, static_argnames=['n']) # this means the variable 'n' is static\n",
        "print(g_jit_correct(10, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVNKaS6PIS_N",
        "outputId": "63a2faeb-a0dc-494e-dc2f-df22f5b0ca7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To specify such arguments when using jit as a decorator, a common pattern is to use python’s functools.partial():"
      ],
      "metadata": {
        "id": "MKyBlYYwImI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jax.jit, static_argnames=['n'])\n",
        "def g_jit_decorated(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    i += 1\n",
        "  return x + i\n",
        "\n",
        "print(g_jit_decorated(10, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z_4CsdKImo1",
        "outputId": "e6631114-b278-40c8-f7ca-8064ad35c374"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JIT and caching"
      ],
      "metadata": {
        "id": "PMVy9kTBLV3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the compilation overhead of the first JIT call, understanding how and when jax.jit() caches previous compilations is key to using it effectively.\n",
        "\n",
        "Suppose we define f = jax.jit(g). When we first invoke f, it will get compiled, and the resulting XLA code will get cached. Subsequent calls of f will reuse the cached code. This is how jax.jit makes up for the up-front cost of compilation.\n",
        "\n",
        "If we specify static_argnums, then the cached code will be used only for the same values of arguments labelled as static. If any of them change, recompilation occurs. If there are many values, then your program might spend more time compiling than it would have executing ops one-by-one.\n",
        "\n",
        "Avoid calling jax.jit() on temporary functions defined inside loops or other Python scopes. For most cases, JAX will be able to use the compiled, cached function in subsequent calls to jax.jit(). However, because the cache relies on the hash of the function, it becomes problematic when equivalent functions are redefined. This will cause unnecessary compilation each time in the loop:"
      ],
      "metadata": {
        "id": "MMWBooJnLYkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "def unjitted_loop_body(prev_i):\n",
        "  return prev_i + 1\n",
        "\n",
        "def g_inner_jitted_partial(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    # Don't do this! each time the partial returns\n",
        "    # a function with different hash\n",
        "    i = jax.jit(partial(unjitted_loop_body))(i) # partial will create a new function oto compile\n",
        "  return x + i\n",
        "\n",
        "def g_inner_jitted_lambda(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    # Don't do this!, lambda will also return\n",
        "    # a function with a different hash\n",
        "    i = jax.jit(lambda x: unjitted_loop_body(x))(i) # lambda will create a new function to cimpile\n",
        "  return x + i\n",
        "\n",
        "def g_inner_jitted_normal(x, n):\n",
        "  i = 0\n",
        "  while i < n:\n",
        "    # this is OK, since JAX can find the\n",
        "    # cached, compiled function\n",
        "    i = jax.jit(unjitted_loop_body)(i) # call the compiled function is ok\n",
        "  return x + i\n",
        "\n",
        "print(\"jit called in a loop with partials:\")\n",
        "%timeit g_inner_jitted_partial(10, 20).block_until_ready()\n",
        "\n",
        "print(\"jit called in a loop with lambdas:\")\n",
        "%timeit g_inner_jitted_lambda(10, 20).block_until_ready()\n",
        "\n",
        "print(\"jit called in a loop with caching:\")\n",
        "%timeit g_inner_jitted_normal(10, 20).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuKfR7ufLaP1",
        "outputId": "0c36ea42-eb03-4dff-d8ea-165df3b8f68b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jit called in a loop with partials:\n",
            "416 ms ± 8.38 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "jit called in a loop with lambdas:\n",
            "523 ms ± 93.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "jit called in a loop with caching:\n",
            "3 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    }
  ]
}